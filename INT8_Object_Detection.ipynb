{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXpTEB1+FfWfSlvX3nts+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayshah1819/tensorrt-int8-practice/blob/main/INT8_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Efl4X7jMJ9r",
        "outputId": "349d3e3d-319f-4bb8-987b-9ed9b48af219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iU  libnvinfer-headers-dev                 10.13.3.9-1+cuda13.0                    amd64        TensorRT development headers\n",
            "iHR libnvinfer10                           10.13.3.9-1+cuda13.0                    amd64        (no description available)\n"
          ]
        }
      ],
      "source": [
        "!dpkg -l | grep nvinfer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPKePPoJPslu",
        "outputId": "f24f3f7e-c157-43ed-f28d-ad5ee15b1ac4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.13.3.9.tar.gz (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13==10.13.3.9 (from tensorrt)\n",
            "  Downloading tensorrt_cu13-10.13.3.9.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_libs==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt)\n",
            "  Downloading tensorrt_cu13_libs-10.13.3.9.tar.gz (706 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_bindings==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt)\n",
            "  Downloading tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Collecting nvidia-cuda-runtime-cu13 (from tensorrt_cu13_libs==10.13.3.9->tensorrt_cu13==10.13.3.9->tensorrt)\n",
            "  Downloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl.metadata (225 bytes)\n",
            "Downloading tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl (1.2 kB)\n",
            "Building wheels for collected packages: tensorrt, tensorrt_cu13, tensorrt_cu13_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.13.3.9-py2.py3-none-any.whl size=46401 sha256=7c01d2355b497d8c6b32800c3a2aae49d2666ffc3eb5f4c55ace3fb63da97d85\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/aa/b0/561559321c1659e43c5a6661986c3072f9c383efeeaaffb1a5\n",
            "  Building wheel for tensorrt_cu13 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13: filename=tensorrt_cu13-10.13.3.9-py2.py3-none-any.whl size=17436 sha256=62a3918754cbe53d4b725720a01bdebebcf394c5568996078af95be766e180e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/4a/b2/ebfc5437a397c53faff0dca4a36c096d4b7d2b7436a2707e60\n",
            "  Building wheel for tensorrt_cu13_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13_libs: filename=tensorrt_cu13_libs-10.13.3.9-py2.py3-none-manylinux_2_28_x86_64.whl size=2740897716 sha256=19a54f2106f7d9496433a01a596fa4e363f58901110306abe1ce7b6e9617c6a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/c2/ab/e79d384901e98797feb52a9ef4e0bbff65c0732f313bfa604f\n",
            "Successfully built tensorrt tensorrt_cu13 tensorrt_cu13_libs\n",
            "Installing collected packages: tensorrt_cu13_bindings, nvidia-cuda-runtime-cu13, tensorrt_cu13_libs, tensorrt_cu13, tensorrt\n",
            "Successfully installed nvidia-cuda-runtime-cu13-0.0.0a0 tensorrt-10.13.3.9 tensorrt_cu13-10.13.3.9 tensorrt_cu13_bindings-10.13.3.9 tensorrt_cu13_libs-10.13.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVvqjuPnQOLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1) Defining the network\n",
        "\n",
        "Step 2) Setting up the INT8 calibrator\n",
        "\n",
        "Step 3) Configuring the builder\n",
        "\n",
        "Step 4) Building the TensorRT engine\n",
        "\n",
        "Step 5) Running inference\n",
        "\n",
        "Step 6) Verifying the output **bold text**"
      ],
      "metadata": {
        "id": "L-rrw8UOOuRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhsoslnmQTlF",
        "outputId": "cddf6513-7869-43f7-84d6-7c23c8823a53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.2.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycuda) (4.4.0)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from pycuda) (1.3.10)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
            "  Downloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.2.4-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1.2-cp312-cp312-linux_x86_64.whl size=659050 sha256=4a951a06e4ab10659acf6c4b7657b889abcd4c6a4659ecfdf1d2fd5f3bbd6869\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/36/f3/ac5f09d768cad3fa15d5a3449bdfe65c3de58e69d036c73228\n",
            "Successfully built pycuda\n",
            "Installing collected packages: siphash24, pytools, pycuda\n",
            "Successfully installed pycuda-2025.1.2 pytools-2025.2.4 siphash24-1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "uIfa2UpJPEqh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Defining the network\n",
        "\n",
        "1.   Prepare Representative Dataset\n",
        "2.   Create INT8 Calibrator\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GZ1sPHGHSOjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_images=np.random.rand(32,3,224,224).astype(np.float32)"
      ],
      "metadata": {
        "id": "-9PSZMXkSFUT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XeotLM9fUMLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCalibrator(trt.IInt8EntropyCalibrator2):\n",
        "    def __init__(self, data, batch_size=8):\n",
        "\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.index = 0\n",
        "        self.device_input = None\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    def get_batch(self, names):\n",
        "        if self.index + self.batch_size > len(self.data):\n",
        "            return None\n",
        "        batch = self.data[self.index:self.index+self.batch_size].ravel()\n",
        "        if self.device_input is None:\n",
        "            self.device_input = cuda.mem_alloc(batch.nbytes)\n",
        "        cuda.memcpy_htod(self.device_input, batch)\n",
        "        self.index += self.batch_size\n",
        "        return [int(self.device_input)]\n",
        "\n",
        "    def read_calibration_cache(self):\n",
        "        return None\n",
        "\n",
        "    def write_calibration_cache(self, cache):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "L3ji2QqiStJa"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}